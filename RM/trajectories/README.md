# Trajectory Generation for AI Agent Planning

This project focuses on generating a synthetic preference dataset of action plans for a variety of tasks. This dataset can be used to train and evaluate AI agents, particularly for reward modeling and plan analysis.

The core idea is to leverage different company personas to generate plans with varying levels of quality and introducing specific, explainable flaws into otherwise correct plans.

## Methodology

The generation process is divided into two main stages: generating positive trajectories and then using those to generate negative trajectories.

### Personas

We use a set of predefined personas to simulate different levels of ML-maturity of a company while generating plans. Each persona has a unique description that influences the complexity, and potential oversights in the generated plans. This allows for a more diverse and realistic dataset.

### Positive Trajectory Generation

Positive trajectories, or correct plans, are generated by the `persona_pos_data.py` script. The process is as follows:

1.  **Task Input**: The process starts with a list of task queries from a CSV file. Each query includes the task, a potential approach, and the reasoning behind that approach.
2.  **Persona-based Plan Generation**: For each task, we iterate through all defined personas. A generative AI model is prompted using the `POS_PROMPT_TEMPLATE` from `prompts.py`.
3.  **Prompting**: The prompt includes the task query, the suggested approach, the reasoning, and the description of the current persona. This guides the model to generate a plan that is consistent with the persona's characteristics.
4.  **Output**: The model returns a JSON object containing the generated `plan` and the `domain` of the task. These are considered the "golden" or correct plans for that persona and task.

### Negative Trajectory Generation

Negative trajectories are created in `persona_neg_data.py` by introducing flaws into the positive trajectories. This is a two-step process:

1.  **Flaw Generation**: For each correct plan generated in the previous step, we prompt the generative model again using the `FLAW_GENERATION_PROMPT_TEMPLATE`. This prompt asks the model to devise a set of flaws or mistakes that could be made when trying to execute the correct plan, again taking the persona's characteristics into account.
2.  **Negative Plan Generation**: The generated flaws are then used in the `NEG_PROMPT_TEMPLATE`. This prompt instructs the model to rewrite the original correct plan, incorporating the specified flaws. The output is a new, incorrect plan.

This two-step process for negative trajectory generation ensures that the flaws are explicit and that the negative plan is a direct, flawed counterpart to a correct plan.

## Code Structure

-   `main.py`: The main script that orchestrates the entire data generation pipeline.
-   `persona_pos_data.py`: Handles the generation of positive (correct) plans.
-   `persona_neg_data.py`: Handles the generation of negative (flawed) plans.
-   `prompts.py`: Contains all the prompt templates used to interact with the generative AI model, as well as the persona definitions.
-   `TS_Sim_Intern_Golden_Tasks_llm-generated-tasks.csv`: The input file containing the initial task queries.
-   `generated_pos_data.json`: The default output file containing the final dataset.

## Output Format

The final output is a JSON file (`generated_pos_data.json`) containing a list of conversations. Each conversation object has the following structure:

```json
{
    "persona_id": "<persona_level>",
    "domain": "<task_domain>",
    "pos_conversation": {
        "human": "<task_query>",
        "agent": "<correct_plan>"
    },
    "flaws": "<generated_flaws>",
    "neg_conversation": {
        "human": "<task_query>",
        "agent": "<negative_plan>"
    }
}
```
